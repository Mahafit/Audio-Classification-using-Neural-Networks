{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4c55ba",
   "metadata": {},
   "source": [
    "#### In this project we will peform EDA on the audio files using Librosa library and use Neural Networks to classify different audio files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf53730",
   "metadata": {},
   "source": [
    "### Time Line of the project :\n",
    "- Importing Libraries and Data set\n",
    "- Data Analysis\n",
    "- Model Building and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b105c68",
   "metadata": {},
   "source": [
    "Data set can be downloaded by this site : https://www.kaggle.com/chrisfilo/urbansound8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee31482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display  #audio visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991eca04",
   "metadata": {},
   "source": [
    "We have different audio files with different sounds. Our aim is to classify the correct lable for the sound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d68fa",
   "metadata": {},
   "source": [
    "#### Reading Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b676941",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr= librosa.load('Urban Sound/fold2/100652-3-0-2.wav')\n",
    "sound= ipd.Audio('Urban Sound/fold2/100652-3-0-2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f462ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaed78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a10098",
   "metadata": {},
   "source": [
    "#### Reading the comman file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= pd.read_csv('Urban Sound/UrbanSound8K.csv')\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f676b8b",
   "metadata": {},
   "source": [
    "We have to create a model which will classify what category of sound the clip belongs to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c4558",
   "metadata": {},
   "source": [
    "For this we will create independent features i.e. different time domain and frequency domain features and dependent labels that are present the the labels csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab57f56",
   "metadata": {},
   "source": [
    "We will extract the features for all the audio files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873d657",
   "metadata": {},
   "source": [
    "#### Extracting Audio Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a677761",
   "metadata": {},
   "source": [
    "1) Zero Crossing Rate : The is the rate at which a signal crosses the negative value to zero and then to a possitive value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77717a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE= 1024\n",
    "HOP_LENGTH= 512\n",
    "ZCR_music = librosa.feature.zero_crossing_rate(audio, frame_length=FRAME_SIZE, hop_length=HOP_LENGTH)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9278c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ZCR_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9416cd9",
   "metadata": {},
   "source": [
    "2) Mel Frequency Cepstral Coefficients : In sound processing, the mel-frequency cepstrum is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. Mel-frequency cepstral coefficients are coefficients that collectively make up an MFC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa80da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs_music = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=10)\n",
    "mfccs_music.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd279ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "librosa.display.specshow(mfccs_music, \n",
    "                         x_axis=\"time\", \n",
    "                         sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd867d6a",
   "metadata": {},
   "source": [
    "Making a fucntion to extract these features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extractor(file_name):\n",
    "    audio, sr= librosa.load(file_name)\n",
    "    mfcc= librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=10)\n",
    "    mfcc_scaled= np.mean(mfcc.T,axis=0)\n",
    "    return mfcc_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr_extractor(file_name):\n",
    "    audio, sr= librosa.load(file_name)\n",
    "    zcr= librosa.feature.zero_crossing_rate(audio, frame_length=FRAME_SIZE, hop_length=HOP_LENGTH)[0]\n",
    "    zcr_scaled= np.mean(zcr.T,axis=0)\n",
    "    return zcr_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b739b06",
   "metadata": {},
   "source": [
    "Extracting from all the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "ind_features=[]\n",
    "audio_dataset_path='Urban Sound'\n",
    "for index_num,row in labels.iterrows():\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    label= row['class']\n",
    "    #print(file_name)\n",
    "    mfcc1= mfcc_extractor(file_name)\n",
    "    #zcr= zcr_extractor(file_name)\n",
    "    ind_features.append([mfcc1,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ind_features=[]\n",
    "audio_dataset_path='Urban Sound'\n",
    "for index_num,row in labels.iterrows():\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    label= row['class']\n",
    "    #print(file_name)\n",
    "    zcr1= zcr_extractor(file_name)\n",
    "    ind_features.append([zcr1,label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ab09b",
   "metadata": {},
   "source": [
    "Now we will convert this into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df= pd.DataFrame(ind_features,columns=['MFCCs','Labels'])\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773bd72c",
   "metadata": {},
   "source": [
    "Now we will split our independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7324ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(features_df['MFCCs'].tolist())  ## independent features\n",
    "y=np.array(features_df['Labels'].tolist())  ## dependent features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f805af8",
   "metadata": {},
   "source": [
    "Performing Label Encoding on the dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y=to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67cd81",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbcbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adee25",
   "metadata": {},
   "source": [
    "#### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c691faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ac160",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "num_labels=y.shape[1]\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(10,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39dfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size= 10, epochs= 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630864a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0930b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model is :\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ee9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17f71d",
   "metadata": {},
   "source": [
    "#### Testing on different audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"Urban Sound/7064-6-0-0.wav\"\n",
    "audio, sample_rate = librosa.load(filename) \n",
    "mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=10)\n",
    "mfccs_mean = np.mean(mfccs.T,axis=0)\n",
    "\n",
    "\n",
    "mfccs_mean=mfccs_mean.reshape(1,-1)\n",
    "predicted_label=model.predict_classes(mfccs_mean)\n",
    "print(predicted_label)\n",
    "prediction_class = le.inverse_transform(predicted_label) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2f73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
